{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bef49e9-feea-4a73-9fbf-792116955b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the spark session \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704bef1f-465a-483a-9067-07a96a229b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LTIN3258.GLOBAL.BCECORP.NET:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f39810f150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check spark session\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6c4e0a-a5ee-4e70-b083-4695df1d1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "df_pyspark = spark.read.option('header','true').csv('test.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a001d9e-e33d-4419-8920-eb119d35a8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75063ca9-d853-4f30-83db-a4487174593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "df_pyspark = spark.read.csv('test.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927cbf93-04fe-4977-bab7-7887bed4323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at the dataset \n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e64865-e70e-4e2a-b8e7-8036a57d7c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d03d137-f167-4bf0-9dce-66ac8385fb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datatype check \n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6595477-80ef-44de-8981-b2e3e0c4f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'department', 'age', 'experience', 'salary']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns name check \n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de495bf7-6c74-42d7-808f-d31cb9ef11ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Bhaskar', department='data science', age=27, experience=10, salary=2000),\n",
       " Row(name='krish', department='IOT', age=31, experience=12, salary=35000),\n",
       " Row(name='Sudhanshu', department='Big data', age=29, experience=24, salary=46999)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 3 data in dataframe\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bf1f61e-3efe-4a9c-ad50-00c75ffe2248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     name|\n",
      "+---------+\n",
      "|  Bhaskar|\n",
      "|    krish|\n",
      "|Sudhanshu|\n",
      "|    krish|\n",
      "|Sudhanshu|\n",
      "|Sudhanshu|\n",
      "|    krish|\n",
      "|   Mahesh|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking data in one specific column\n",
    "df_pyspark.select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a267f5c1-807f-4244-90ce-a96b54775220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "081ce5dd-40f9-4984-83e8-c9111905fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|  Bhaskar| 27|\n",
      "|    krish| 31|\n",
      "|Sudhanshu| 29|\n",
      "|    krish| 21|\n",
      "|Sudhanshu| 23|\n",
      "|Sudhanshu| 44|\n",
      "|    krish| 33|\n",
      "|   Mahesh| 34|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting multiple columns \n",
    "df_pyspark.select(['name', 'age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274a164d-834a-44d2-adb1-59fd31e8d937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'),\n",
       " ('department', 'string'),\n",
       " ('age', 'int'),\n",
       " ('experience', 'int'),\n",
       " ('salary', 'int')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking datatypes\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8b51de-48bc-4ce0-a024-e08aa5334496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------------+-----------------+------------------+\n",
      "|summary|   name|  department|              age|       experience|            salary|\n",
      "+-------+-------+------------+-----------------+-----------------+------------------+\n",
      "|  count|      8|           8|                8|                8|                 8|\n",
      "|   mean|   NULL|        NULL|            30.25|             8.25|           72351.5|\n",
      "| stddev|   NULL|        NULL|7.186296483088988|7.611082145698563|112980.42651716269|\n",
      "|    min|Bhaskar|    Big data|               21|                1|                45|\n",
      "|    max|  krish|data science|               44|               24|            346768|\n",
      "+-------+-------+------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f3e6044-bb1f-4120-b0ac-244dbda3a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one column in given dataset\n",
    "df_pyspark = df_pyspark.withColumn('Exp after 2 years', df_pyspark.experience + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "927461a4-30c2-4228-b410-6f1bec3f4e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+-----------------+\n",
      "|     name|  department|age|experience|salary|Exp after 2 years|\n",
      "+---------+------------+---+----------+------+-----------------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|               12|\n",
      "|    krish|         IOT| 31|        12| 35000|               14|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|               26|\n",
      "|    krish|    Big data| 21|         1| 50000|                3|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|                4|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|                5|\n",
      "|    krish|data science| 33|         4|    45|                6|\n",
      "|   Mahesh|data science| 34|        10| 38000|               12|\n",
      "+---------+------------+---+----------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dcfd79b-0a8a-476f-8ed6-94735ea13970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the column\n",
    "df_pyspark = df_pyspark.drop('Exp after 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b72ac3a8-c321-4418-b0f2-32eeb6ce6c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f91a3d7-3337-4ff7-b9ec-bfef6201fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename a column\n",
    "df_pyspark = df_pyspark.withColumnRenamed('name', 'new_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c56124-0a55-4cfe-a908-498164051381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "| new_name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81532b-b8bb-41b2-9ca8-b52cdb1408ea",
   "metadata": {},
   "source": [
    "### Pyspark video 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8490db-5e2d-4fb5-9bed-65c34762d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the spark session \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f5b665a-1154-48e0-b822-cde72e99baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading a csv file\n",
    "df_pyspark = spark.read.csv('test.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ccadae6-b61a-41b5-89d0-606f9b67da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1505d33-89af-4a22-861d-6b8c811d62ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping null values \n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb227e56-0870-40fb-bc92-eff35f383900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0a9ba0-9e78-4441-a506-fb23180d1ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(subset = ['experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a848d17-a599-42c7-afb2-67713e749ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing value imputation \n",
    "df_pyspark.na.fill('Missing Values', ['age','experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf85d77f-43d9-4e80-8359-3931bf0f277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8720012-5f99-45dc-a25d-2187943f7df3",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "##### & | ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "665c495f-02ee-4e09-9608-197b77125032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+---+----------+------+\n",
      "|   name|  department|age|experience|salary|\n",
      "+-------+------------+---+----------+------+\n",
      "|Bhaskar|data science| 27|        10|  2000|\n",
      "|  krish|data science| 33|         4|    45|\n",
      "+-------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"salary <= 20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d4ff74f-7ecf-4a84-bc67-c8f98cf66842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Bhaskar| 27|\n",
      "|  krish| 33|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"salary <= 20000\").select(['name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7df3e516-98a8-4e83-80dd-bbb5914d9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple filters \n",
    "df_pyspark.filter((df_pyspark['salary'] >= 20000) & \n",
    "                  (df_pyspark['age'] > 20)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cef55ac0-3821-498e-8ec1-94b4ed433559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('practive').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3258716-f62d-4a58-af08-ec3784c548ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test.csv',header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38a60bc8-bded-4a53-ab50-b05b8b90e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---+----------+------+\n",
      "|     name|  department|age|experience|salary|\n",
      "+---------+------------+---+----------+------+\n",
      "|  Bhaskar|data science| 27|        10|  2000|\n",
      "|    krish|         IOT| 31|        12| 35000|\n",
      "|Sudhanshu|    Big data| 29|        24| 46999|\n",
      "|    krish|    Big data| 21|         1| 50000|\n",
      "|Sudhanshu|    Big data| 23|         2|346768|\n",
      "|Sudhanshu|         IOT| 44|         3| 60000|\n",
      "|    krish|data science| 33|         4|    45|\n",
      "|   Mahesh|data science| 34|        10| 38000|\n",
      "+---------+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc4f1869-3b89-4c7e-85eb-71eb14d326c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad88afbd-c3fd-4ff6-8031-e72a622483e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|     453767|\n",
      "|  Bhaskar|       2000|\n",
      "|    krish|      85045|\n",
      "|   Mahesh|      38000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy to find the maximum salary \n",
    "\n",
    "df_pyspark.groupby('name').sum('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d624390a-b8a7-48d8-aa5f-14c154950c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|  department|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      95000|\n",
      "|data science|      40045|\n",
      "|    Big data|     443767|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy department which get the maximum salary\n",
    "\n",
    "df_pyspark.groupby('department').sum('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4184eee7-2e41-4af6-b28c-2caf9d57bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|  department|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|data science|    3|\n",
      "|    Big data|    3|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy department and count there occurance\n",
    "df_pyspark.groupby('department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea544241-5b18-4a1a-8086-299d3aead8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|     578812|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad021a62-f7de-44aa-abb7-52defc61f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|  department|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      95000|\n",
      "|data science|      40045|\n",
      "|    Big data|     443767|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby('department').agg({'salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "825b8c1a-652f-425a-968b-2f383e0002b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|     453767|\n",
      "|  Bhaskar|       2000|\n",
      "|    krish|      85045|\n",
      "|   Mahesh|      38000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby('name').sum('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a48380-4056-4093-8057-64e9b5de622d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
